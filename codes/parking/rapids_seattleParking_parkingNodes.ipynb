{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where are the parking spots?\n",
    "## Using RAPIDS to find proper distances to parking spots\n",
    "\n",
    "## Load the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cuspatial\n",
    "import nvstrings\n",
    "import nvtext\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import cugraph\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.56 s\n"
     ]
    }
   ],
   "source": [
    "dtypes = OrderedDict([\n",
    "    ('OccupancyDateTime', 'date'),\n",
    "    ('PaidOccupancy', 'int64'),\n",
    "    ('BlockfaceName', 'str'),\n",
    "    ('SideOfStreet', 'str'),\n",
    "    ('SourceElementKey', 'int64'),\n",
    "    ('ParkingTimeLimitCategory', 'int64'),\n",
    "    ('ParkingSpaceCount', 'int64'),\n",
    "    ('PaidParkingArea', 'str'),\n",
    "    ('PaidParkingSubArea', 'str'),\n",
    "    ('PaidParkingRate', 'int8'),\n",
    "    ('ParkingCategory', 'str'),\n",
    "    ('Location', 'str'),\n",
    "    ('dow', 'int8')\n",
    "])\n",
    "\n",
    "df = cudf.read_csv(\n",
    "    '../data/parking_MayJun2019.csv'\n",
    "    , skiprows=1\n",
    "    , dtype=list(dtypes.values())\n",
    "    , names=list(dtypes.keys())\n",
    ")\n",
    "\n",
    "df = df[['SourceElementKey', 'Location']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the geo-coordinates for the parking locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 701 Âµs\n"
     ]
    }
   ],
   "source": [
    "def extractLon(location):\n",
    "    lon = location.str.extract('([0-9\\.\\-]+) ([0-9\\.]+)')[0]\n",
    "    return lon.str.stod()\n",
    "\n",
    "def extractLat(location):\n",
    "    lon = location.str.extract('([0-9\\.\\-]+) ([0-9\\.]+)')[1]\n",
    "    return lon.str.stod()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.97 s\n"
     ]
    }
   ],
   "source": [
    "locations = df.drop_duplicates()\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 266 ms\n"
     ]
    }
   ],
   "source": [
    "locations['longitude'] = extractLon(locations['Location'])\n",
    "locations['latitude'] = extractLat(locations['Location'])\n",
    "locations = locations[['SourceElementKey', 'longitude', 'latitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we'll use the Nomatim encoder to find the coordinates of the Space Needle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location(Space Needle, 400, Broad Street, South Lake Union, Belltown, Seattle, King County, Washington, 98109, USA, (47.6205131, -122.349303598832, 0.0))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 856 ms\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"todrabas_test\")\n",
    "location = geolocator.geocode(\"400 Broad St, Seattle, WA 98109\") # SPACE NEEDLE\n",
    "\n",
    "location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As crow flies vs as people walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the graph data\n",
    "Thanks to John Murray for analyzing the map of King County roads and producing the data we will now use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and unpack the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.52 ms\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory  = os.path.exists('../data')\n",
    "archive    = os.path.exists('../data/king_county_road_graph_20190909.tar.gz')\n",
    "file_graph = os.path.exists('../data/king_county_road_graph_20190909.csv')\n",
    "file_nodes = os.path.exists('../data/king_county_road_nodes_20190909.csv')\n",
    "\n",
    "if not directory:\n",
    "    os.mkdir('../data')\n",
    "\n",
    "if not archive:\n",
    "    import wget, shutil\n",
    "    \n",
    "    wget.download('http://tomdrabas.com/data/seattle_parking/king_county_road_graph_20190909.tar.gz')\n",
    "    shutil.move('king_county_road_graph_20190909.tar.gz', '../data/king_county_road_graph_20190909.tar.gz')\n",
    "    \n",
    "if not file_graph or not file_nodes:\n",
    "    import tarfile\n",
    "\n",
    "    tf = tarfile.open('../data/king_county_road_graph_20190909.tar.gz')\n",
    "    tf.extractall(path='../data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's read the King County road data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.5 ms\n"
     ]
    }
   ],
   "source": [
    "road_graph_data = cudf.read_csv('../data/king_county_road_graph_20190909.csv')\n",
    "road_graph_data['node1'] = road_graph_data['node1'].astype('int32')\n",
    "road_graph_data['node2'] = road_graph_data['node2'].astype('int32')\n",
    "road_graph_data['LENGTH'] = road_graph_data['LENGTH'] * 3 # convert to feet as the LENGHT was given in yards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.51 ms\n"
     ]
    }
   ],
   "source": [
    "road_nodes = cudf.read_csv('../data/king_county_road_nodes_20190909.csv')\n",
    "road_nodes['NodeID'] = road_nodes['NodeID'].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the maximum of the `NodeID` so we can later append the additional nodes that will be perpendicular to the actual parking locations. We also specify the offset - this will be used to append parking nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127380"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.36 ms\n"
     ]
    }
   ],
   "source": [
    "offset = 100000\n",
    "nodeId = road_nodes['NodeID'].max()                       ## so we can number the parking nodes properly (since we'll be adding a perpendicular projections)\n",
    "parking_nodes_idx = road_nodes['NodeID'].max() + offset   ## retain it so we can later filter the results to only parking locations\n",
    "nodeId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move all the parking locations to host (via `.to_pandas()` method) so we can loop through all the ~1500 parking locations. Here, we also create an empty DataFrame that will hold the parking location nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 131 ms\n"
     ]
    }
   ],
   "source": [
    "parking_locations = locations.to_pandas().to_dict('records')\n",
    "parking_locations_nodes = cudf.DataFrame(columns=['NodeID', 'Lon', 'Lat', 'SourceElementKey'])\n",
    "added_location_edges    = cudf.DataFrame(columns=['node1', 'node2', 'LENGTH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's process the parking data. The kernel below finds equations of two lines:\n",
    "\n",
    "1. Line that goes through road intersections\n",
    "2. Line that is perpendicular to (1) and goes through the parking location.\n",
    "\n",
    "Ultimately, we are finind the intersection of these two lines -- we call it the `PROJ` point below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.43 ms\n"
     ]
    }
   ],
   "source": [
    "def kernel_find_projection(Lon_x, Lat_x, Lon_y, Lat_y, Lon_PROJ, Lat_PROJ, Lon_REF, Lat_REF):\n",
    "    for i, (lon_x, lat_x, lon_y, lat_y) in enumerate(zip(Lon_x, Lat_x, Lon_y, Lat_y)):\n",
    "        # special case where A and B have the same LON i.e. vertical line\n",
    "        if lon_x == lon_y:\n",
    "            Lon_PROJ[i] = lon_x\n",
    "            Lat_PROJ[i] = Lat_REF    \n",
    "        else:\n",
    "            # find slope\n",
    "            a_xy = (lat_x - lat_y) / float(lon_x - lon_y)\n",
    "\n",
    "            # special case where A and B have the same LAT i.e. horizontal line\n",
    "            if a_xy == 0:\n",
    "                Lon_PROJ[i] = Lon_REF\n",
    "                Lat_PROJ[i] = lat_x\n",
    "            else: \n",
    "                # if neither of the above special cases apply\n",
    "                # find the equation of the perpendicular line\n",
    "                a_R  = -1 / a_xy                    ### SLOPE\n",
    "\n",
    "                # find intersections\n",
    "                b_xy = lat_x - a_xy * lon_x\n",
    "                b_R  = Lat_REF - a_R  * Lon_REF\n",
    "\n",
    "                # find the coordinates\n",
    "                Lon_PROJ[i] = (b_R - b_xy) / (a_xy - a_R)\n",
    "                Lat_PROJ[i] = a_R * Lon_PROJ[i] + b_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parking locations: 1,473\n",
      "Processed: 0 (0.000000%) nodes\n",
      "Processed: 100 (6.788866%) nodes\n",
      "Processed: 200 (13.577733%) nodes\n",
      "Processed: 300 (20.366599%) nodes\n",
      "Processed: 400 (27.155465%) nodes\n",
      "Processed: 500 (33.944331%) nodes\n",
      "Processed: 600 (40.733198%) nodes\n",
      "Processed: 700 (47.522064%) nodes\n",
      "Processed: 800 (54.310930%) nodes\n",
      "Processed: 900 (61.099796%) nodes\n",
      "Processed: 1,000 (67.888663%) nodes\n",
      "Processed: 1,100 (74.677529%) nodes\n",
      "Processed: 1,200 (81.466395%) nodes\n",
      "Processed: 1,300 (88.255261%) nodes\n",
      "Processed: 1,400 (95.044128%) nodes\n",
      "Finished processing...\n",
      "time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "parking_locations_cnt = len(parking_locations)\n",
    "print('Number of parking locations: {0:,}'.format(parking_locations_cnt))\n",
    "\n",
    "for i, loc in enumerate(parking_locations):\n",
    "    if i % 100 == 0:\n",
    "        print('Processed: {0:,} ({1:2%}) nodes'.format(i, i/float(parking_locations_cnt)))\n",
    "        \n",
    "    #### INCREASE THE COUNTER AND GET THE REFERENCE POINT\n",
    "    nodeId = nodeId + 1\n",
    "    lat_r = loc['latitude']\n",
    "    lon_r = loc['longitude']\n",
    "\n",
    "    #### APPEND GEO COORDINATES TO INTERSECTION AND SUBSET DOWN THE DATASET\n",
    "    #### TO POINTS WITHIN ~2000ft FROM PARKING SPOT\n",
    "    paths = (\n",
    "        road_graph_data\n",
    "        .rename({'node1': 'NodeID'})\n",
    "        .merge(road_nodes[['NodeID', 'Lat', 'Lon']], on='NodeID', how='left')\n",
    "        .rename({'NodeID': 'node1', 'node2': 'NodeID'})\n",
    "        .merge(road_nodes[['NodeID', 'Lat', 'Lon']], on='NodeID', how='left')\n",
    "        .rename({'NodeID': 'node2'})\n",
    "        .query('Lat_x >= (@lat_r - 0.005) and Lat_x <= (@lat_r + 0.005)')\n",
    "        .query('Lon_x >= (@lon_r - 0.005) and Lon_x <= (@lon_r + 0.005)')\n",
    "        .query('Lat_y >= (@lat_r - 0.005) and Lat_y <= (@lat_r + 0.005)')\n",
    "        .query('Lon_y >= (@lon_r - 0.005) and Lon_y <= (@lon_r + 0.005)')\n",
    "    )\n",
    "\n",
    "    #### APPEND THE PARKING LOCATION SO WE CAN CALCULATE DISTANCES\n",
    "    paths['Lon_REF'] = loc['longitude']\n",
    "    paths['Lat_REF'] = loc['latitude']\n",
    "\n",
    "    paths = paths.apply_rows(\n",
    "        kernel_find_projection\n",
    "        , incols  = ['Lon_x', 'Lat_x', 'Lon_y', 'Lat_y', 'Lon_REF', 'Lat_REF']\n",
    "        , outcols = {'Lon_PROJ': np.float64, 'Lat_PROJ': np.float64}\n",
    "        , kwargs  = {'Lon_REF': loc['longitude'], 'Lat_REF': loc['latitude']}\n",
    "    )\n",
    "\n",
    "    #### CALCULATE THE DISTANCES SO WE CAN CHECK IF THE PROJ POINT IS BETWEEN ROAD NODES\n",
    "    paths['Length_x_PROJ'] = cuspatial.haversine_distance(\n",
    "              paths['Lon_x']\n",
    "            , paths['Lat_x']\n",
    "            , paths['Lon_PROJ']\n",
    "            , paths['Lat_PROJ']) * 0.621371 * 5280\n",
    "\n",
    "    paths['Length_y_PROJ'] = cuspatial.haversine_distance(\n",
    "              paths['Lon_y']\n",
    "            , paths['Lat_y']\n",
    "            , paths['Lon_PROJ']\n",
    "            , paths['Lat_PROJ']) * 0.621371 * 5280\n",
    "\n",
    "    paths['Length_REF_PROJ'] = cuspatial.haversine_distance(\n",
    "              paths['Lon_REF']\n",
    "            , paths['Lat_REF']\n",
    "            , paths['Lon_PROJ']\n",
    "            , paths['Lat_PROJ']) * 0.621371 * 5280\n",
    "\n",
    "    #### SELECT THE POINTS THAT A LESS THAN OR EQAL TO TOTAL LENGTH OF THE EDGE (WITHIN 1 ft)\n",
    "    paths['PROJ_between'] = (paths['Length_x_PROJ'] + paths['Length_y_PROJ']) <= (paths['LENGTH'] + 1)\n",
    "    \n",
    "    #### SELECT THE CLOSEST\n",
    "    closest = (\n",
    "        paths\n",
    "        .query('PROJ_between')\n",
    "        .nsmallest(1, 'Length_REF_PROJ')\n",
    "        .to_pandas()\n",
    "        .to_dict('records')[0]\n",
    "    )\n",
    "\n",
    "    # add nodes\n",
    "    nodes =    cudf.DataFrame({\n",
    "          'NodeID': [nodeId + offset, nodeId]\n",
    "        , 'Lon':    [closest['Lon_REF'], closest['Lon_PROJ']]\n",
    "        , 'Lat':    [closest['Lat_REF'], closest['Lat_PROJ']]\n",
    "        , 'SourceElementKey': [loc['SourceElementKey'], None]\n",
    "    })\n",
    "\n",
    "    parking_locations_nodes = cudf.concat([parking_locations_nodes, nodes])\n",
    "\n",
    "    # add edges (bi-directional)\n",
    "    edges = cudf.DataFrame({\n",
    "          'node1':  [nodeId, nodeId, nodeId, closest['node1'], closest['node2'], nodeId + offset]\n",
    "        , 'node2':  [closest['node1'], closest['node2'], nodeId + offset, nodeId, nodeId, nodeId]\n",
    "        , 'LENGTH': [\n",
    "              closest['Length_x_PROJ'], closest['Length_y_PROJ'], closest['Length_REF_PROJ']\n",
    "            , closest['Length_x_PROJ'], closest['Length_y_PROJ'], closest['Length_REF_PROJ']\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    added_location_edges = cudf.concat([added_location_edges, edges]) ## append to the temp DataFrame\n",
    "\n",
    "print('Finished processing...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 62.1 ms\n"
     ]
    }
   ],
   "source": [
    "road_nodes = (\n",
    "    cudf\n",
    "    .concat([road_nodes[['NodeID', 'Lon', 'Lat']], parking_locations_nodes])\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the nearest intersections from the Space Needle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47756</th>\n",
       "      <td>128855</td>\n",
       "      <td>47757</td>\n",
       "      <td>175.906391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80448</th>\n",
       "      <td>128855</td>\n",
       "      <td>80449</td>\n",
       "      <td>200.062128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96739</th>\n",
       "      <td>128855</td>\n",
       "      <td>96740</td>\n",
       "      <td>261.056715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108797</th>\n",
       "      <td>128855</td>\n",
       "      <td>108798</td>\n",
       "      <td>277.221141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47827</th>\n",
       "      <td>128855</td>\n",
       "      <td>47828</td>\n",
       "      <td>301.715490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         node1   node2      LENGTH\n",
       "47756   128855   47757  175.906391\n",
       "80448   128855   80449  200.062128\n",
       "96739   128855   96740  261.056715\n",
       "108797  128855  108798  277.221141\n",
       "47827   128855   47828  301.715490"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 100 ms\n"
     ]
    }
   ],
   "source": [
    "road_nodes['Lon_REF'] = location.longitude\n",
    "road_nodes['Lat_REF'] = location.latitude\n",
    "\n",
    "road_nodes['Distance'] = cuspatial.haversine_distance(\n",
    "          road_nodes['Lon']\n",
    "        , road_nodes['Lat']\n",
    "        , road_nodes['Lon_REF']\n",
    "        , road_nodes['Lat_REF']) * 0.621371 * 5280\n",
    "\n",
    "space_needle_to_nearest_intersection = road_nodes.nsmallest(5, 'Distance') ### Space Needle is surrounded by around 5 road intersections hence we add 5\n",
    "space_needle_to_nearest_intersection_dist = space_needle_to_nearest_intersection['Distance'].to_array()[0]\n",
    "\n",
    "space_needle_to_nearest_intersection['node1'] = nodeId + 2\n",
    "space_needle_to_nearest_intersection = (\n",
    "    space_needle_to_nearest_intersection\n",
    "    .rename({'NodeID': 'node2', 'Distance': 'LENGTH'})\n",
    "    [['node1', 'node2', 'LENGTH']]\n",
    ")\n",
    "\n",
    "road_graph_data = cudf.concat([space_needle_to_nearest_intersection, added_location_edges, road_graph_data])\n",
    "space_needle_to_nearest_intersection ### SHOW THE EDGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The road graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.06 ms\n"
     ]
    }
   ],
   "source": [
    "road_graph_data = road_graph_data.reset_index(drop=True)\n",
    "road_graph_data['node1'] = road_graph_data['node1'].astype('int32')\n",
    "road_graph_data['node2'] = road_graph_data['node2'].astype('int32')\n",
    "\n",
    "sources      = cudf.Series(road_graph_data['node1'])\n",
    "destinations = cudf.Series(road_graph_data['node2'])\n",
    "distances    = cudf.Series(road_graph_data['LENGTH'])\n",
    "\n",
    "g = cugraph.Graph()\n",
    "g.add_edge_list(sources, destinations, distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `.sssp(...)` method from `cugraph` to find the shortest distances to parking spots from the Space Needle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vertex</th>\n",
       "      <th>distance</th>\n",
       "      <th>predecessor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227585</th>\n",
       "      <td>227585</td>\n",
       "      <td>494.541097</td>\n",
       "      <td>127585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227586</th>\n",
       "      <td>227586</td>\n",
       "      <td>471.843339</td>\n",
       "      <td>127586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227666</th>\n",
       "      <td>227666</td>\n",
       "      <td>978.714937</td>\n",
       "      <td>127666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227667</th>\n",
       "      <td>227667</td>\n",
       "      <td>986.632352</td>\n",
       "      <td>127667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227822</th>\n",
       "      <td>227822</td>\n",
       "      <td>978.340665</td>\n",
       "      <td>127822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227823</th>\n",
       "      <td>227823</td>\n",
       "      <td>954.882271</td>\n",
       "      <td>127823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227912</th>\n",
       "      <td>227912</td>\n",
       "      <td>796.521774</td>\n",
       "      <td>127912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227913</th>\n",
       "      <td>227913</td>\n",
       "      <td>793.130111</td>\n",
       "      <td>127913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228160</th>\n",
       "      <td>228160</td>\n",
       "      <td>587.108025</td>\n",
       "      <td>128160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228161</th>\n",
       "      <td>228161</td>\n",
       "      <td>542.478604</td>\n",
       "      <td>128161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228224</th>\n",
       "      <td>228224</td>\n",
       "      <td>982.444003</td>\n",
       "      <td>128224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228506</th>\n",
       "      <td>228506</td>\n",
       "      <td>783.243667</td>\n",
       "      <td>128506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        vertex    distance  predecessor\n",
       "227585  227585  494.541097       127585\n",
       "227586  227586  471.843339       127586\n",
       "227666  227666  978.714937       127666\n",
       "227667  227667  986.632352       127667\n",
       "227822  227822  978.340665       127822\n",
       "227823  227823  954.882271       127823\n",
       "227912  227912  796.521774       127912\n",
       "227913  227913  793.130111       127913\n",
       "228160  228160  587.108025       128160\n",
       "228161  228161  542.478604       128161\n",
       "228224  228224  982.444003       128224\n",
       "228506  228506  783.243667       128506"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 177 ms\n"
     ]
    }
   ],
   "source": [
    "all_distances = cugraph.sssp(g, nodeId + 2)\n",
    "distances = all_distances.query('vertex > @parking_nodes_idx and distance < 1000')\n",
    "distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cugraph` returns a DataFrame with vertex, distance to that vertex, and the total distance traveled to that vertex from the `nodeId + 1` node -- the Space Needle. Here, we unfold the full path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing record: 0\n",
      "Processing record: 1\n",
      "Processing record: 2\n",
      "Processing record: 3\n",
      "Processing record: 4\n",
      "Processing record: 5\n",
      "Processing record: 6\n",
      "Processing record: 7\n",
      "Processing record: 8\n",
      "Processing record: 9\n",
      "Processing record: 10\n",
      "Processing record: 11\n",
      "time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "# unfold -- create the whole path\n",
    "closest_node = nodeId + 2\n",
    "parking_cnt = distances['vertex'].count()\n",
    "\n",
    "for i in range(parking_cnt):\n",
    "    print('Processing record: {0}'.format(i))\n",
    "    parking_node = distances.iloc[i]\n",
    "    vertex = int(parking_node[0])\n",
    "    predecessor = int(parking_node[2])\n",
    "    \n",
    "    if i == 0:\n",
    "        paths = all_distances.query('vertex == @vertex')\n",
    "    else:\n",
    "        paths = cudf.concat([all_distances.query('vertex == @vertex'), paths])\n",
    "\n",
    "    while vertex != closest_node:\n",
    "        temp = all_distances.query('vertex == @predecessor')\n",
    "        paths = cudf.concat([temp, paths])\n",
    "        predecessor = temp['predecessor'].to_array()[0]\n",
    "        vertex = temp['vertex'].to_array()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charting the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 127 ms\n"
     ]
    }
   ],
   "source": [
    "paths['vertex'] = paths['vertex'].astype('int64')\n",
    "paths['predecessor'] = paths['predecessor'].astype('int64')\n",
    "paths = paths.drop_duplicates()\n",
    "\n",
    "### process the data so we get the Lat/Lon back for both src and dest\n",
    "### then move to host\n",
    "paths_host = (\n",
    "    paths\n",
    "    .rename({'vertex': 'NodeID'})\n",
    "    .merge(road_nodes[['NodeID', 'Lat', 'Lon']], on='NodeID', how='left')\n",
    "    .rename({'NodeID': 'vertex', 'predecessor': 'NodeID'})\n",
    "    .merge(road_nodes[['NodeID', 'Lat', 'Lon']], on='NodeID', how='left')\n",
    "    .fillna({'Lat_y': location.latitude, 'Lon_y': location.longitude})\n",
    "    [['vertex', 'Lat_x', 'Lon_x', 'Lat_y', 'Lon_y']]\n",
    "    .query('vertex != @nodeId + 2')\n",
    "    .to_pandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the information about the parking spots so we can create info boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.7 ms\n"
     ]
    }
   ],
   "source": [
    "distances['vertex'] = distances['vertex'].astype('int64')\n",
    "distances_host = (\n",
    "    distances\n",
    "    .rename({'vertex': 'NodeID'})\n",
    "    .merge(road_nodes[['NodeID', 'Lat', 'Lon', 'SourceElementKey']], on='NodeID')\n",
    "    [['SourceElementKey', 'Lat', 'Lon', 'distance']]\n",
    "    .to_pandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.08 ms\n"
     ]
    }
   ],
   "source": [
    "info_box_template = \"\"\"\n",
    "<dl>\n",
    "<dt><dd>SourceElementKey</dd><dd>{SourceElementKey}</dd></dt>\n",
    "<dt><dd>Distance        </dd><dd>{distance:.0f} ft.</dd></dt>\n",
    "</dl>\n",
    "\"\"\"\n",
    "\n",
    "parking_info = [info_box_template.format(**parking) for parking in distances_host.to_dict('records')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And... plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96a912512464443a58201b80860b1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 104 ms\n"
     ]
    }
   ],
   "source": [
    "import gmaps\n",
    "\n",
    "with open('config/GoogleMapsAPI.cred', 'r') as f:\n",
    "    cred = f.read()\n",
    "gmaps.configure(api_key=cred) # Your Google API key, go to https://console.developers.google.com\n",
    "\n",
    "parking_layer = gmaps.symbol_layer(\n",
    "    distances_host[['Lat', 'Lon']], fill_color=\"green\", stroke_color=\"green\", scale=3, info_box_content=parking_info\n",
    ")\n",
    "\n",
    "destinations_layer = gmaps.symbol_layer(\n",
    "    [[location.latitude, location.longitude]]\n",
    "    , info_box_content=['DESTINATION']\n",
    "    , scale=5\n",
    "    , fill_color=\"red\"\n",
    "    , stroke_color=\"red\"\n",
    ")\n",
    "\n",
    "lines_layer = gmaps.drawing_layer(features=[\n",
    "    gmaps.Line(\n",
    "          start = (path['Lat_x'], path['Lon_x'])\n",
    "        , end   = (path['Lat_y'], path['Lon_y'])\n",
    "        , stroke_weight=2\n",
    "        , stroke_color=\"red\"\n",
    "    )\n",
    "    for path in paths_host.to_dict('records')]\n",
    ")\n",
    "\n",
    "fig = gmaps.figure(layout={'height': '500px'})\n",
    "fig.add_layer(parking_layer)\n",
    "fig.add_layer(destinations_layer)\n",
    "fig.add_layer(lines_layer)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map above won't cache but here's what you should be seeing \n",
    "\n",
    "<img src=\"../images/parkingNodes.png\" alt=\"Finding shortest path\" style=\"height: 400px;\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
